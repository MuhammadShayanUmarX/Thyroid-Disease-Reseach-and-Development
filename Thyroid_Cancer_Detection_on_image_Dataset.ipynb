{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX6Y8cGXT1ln"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZYGyG5khHDW",
        "outputId": "f7aecd91-227c-400e-bebc-7ed7db3389fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTg0Ay81b0J5",
        "outputId": "08403e3a-2616-4a0d-80bf-415f05f02892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/azouzmaroua/algeria-ultrasound-images-thyroid-dataset-auitd\n",
            "License(s): unknown\n",
            "Downloading algeria-ultrasound-images-thyroid-dataset-auitd.zip to /content\n",
            " 97% 100M/103M [00:05<00:00, 21.7MB/s] \n",
            "100% 103M/103M [00:05<00:00, 19.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download dataset from Kaggle\n",
        "!kaggle datasets download -d azouzmaroua/algeria-ultrasound-images-thyroid-dataset-auitd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPARsVcGUMN7",
        "outputId": "a3fb92d9-01b9-439c-df39-dc00d555a668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Dataset URL: https://www.kaggle.com/datasets/azouzmaroua/algeria-ultrasound-images-thyroid-dataset-auitd\n",
            "License(s): unknown\n",
            "algeria-ultrasound-images-thyroid-dataset-auitd.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Epoch 1/20\n",
            "Train Loss: 1.0616\n",
            "Test Metrics - Acc: 0.2869 | Prec: 0.8646 | Rec: 0.2869 | F1: 0.2621\n",
            "Epoch 2/20\n",
            "Train Loss: 1.0459\n",
            "Test Metrics - Acc: 0.1838 | Prec: 0.8613 | Rec: 0.1838 | F1: 0.0666\n",
            "Epoch 3/20\n",
            "Train Loss: 0.9961\n",
            "Test Metrics - Acc: 0.1838 | Prec: 0.8585 | Rec: 0.1838 | F1: 0.0662\n",
            "Epoch 4/20\n",
            "Train Loss: 0.9150\n",
            "Test Metrics - Acc: 0.6490 | Prec: 0.8868 | Rec: 0.6490 | F1: 0.6906\n",
            "Epoch 5/20\n",
            "Train Loss: 0.9075\n",
            "Test Metrics - Acc: 0.9192 | Prec: 0.9163 | Rec: 0.9192 | F1: 0.9172\n",
            "Epoch 6/20\n",
            "Train Loss: 0.9008\n",
            "Test Metrics - Acc: 0.9220 | Prec: 0.9220 | Rec: 0.9220 | F1: 0.9220\n",
            "Epoch 7/20\n",
            "Train Loss: 0.8520\n",
            "Test Metrics - Acc: 0.7660 | Prec: 0.9025 | Rec: 0.7660 | F1: 0.7945\n",
            "Epoch 8/20\n",
            "Train Loss: 0.8718\n",
            "Test Metrics - Acc: 0.1866 | Prec: 0.8614 | Rec: 0.1866 | F1: 0.0682\n",
            "Epoch 9/20\n",
            "Train Loss: 0.8261\n",
            "Test Metrics - Acc: 0.1866 | Prec: 0.8614 | Rec: 0.1866 | F1: 0.0682\n",
            "Epoch 10/20\n",
            "Train Loss: 0.8139\n",
            "Test Metrics - Acc: 0.1866 | Prec: 0.8614 | Rec: 0.1866 | F1: 0.0682\n",
            "Epoch 11/20\n",
            "Train Loss: 0.7945\n",
            "Test Metrics - Acc: 0.2618 | Prec: 0.8637 | Rec: 0.2618 | F1: 0.2124\n",
            "Epoch 12/20\n",
            "Train Loss: 0.7814\n",
            "Test Metrics - Acc: 0.2981 | Prec: 0.8650 | Rec: 0.2981 | F1: 0.2694\n",
            "Epoch 13/20\n",
            "Train Loss: 0.7565\n",
            "Test Metrics - Acc: 0.5097 | Prec: 0.8754 | Rec: 0.5097 | F1: 0.5498\n",
            "Epoch 14/20\n",
            "Train Loss: 0.7828\n",
            "Test Metrics - Acc: 0.8273 | Prec: 0.9151 | Rec: 0.8273 | F1: 0.8465\n",
            "Epoch 15/20\n",
            "Train Loss: 0.7810\n",
            "Test Metrics - Acc: 0.7159 | Prec: 0.8948 | Rec: 0.7159 | F1: 0.7511\n",
            "Epoch 16/20\n",
            "Train Loss: 0.7380\n",
            "Test Metrics - Acc: 0.4958 | Prec: 0.8745 | Rec: 0.4958 | F1: 0.5342\n",
            "Epoch 17/20\n",
            "Train Loss: 0.7598\n",
            "Test Metrics - Acc: 0.5989 | Prec: 0.8820 | Rec: 0.5989 | F1: 0.6426\n",
            "Epoch 18/20\n",
            "Train Loss: 0.7505\n",
            "Test Metrics - Acc: 0.3064 | Prec: 0.8653 | Rec: 0.3064 | F1: 0.2827\n",
            "Epoch 19/20\n",
            "Train Loss: 0.7386\n",
            "Test Metrics - Acc: 0.5181 | Prec: 0.8759 | Rec: 0.5181 | F1: 0.5590\n",
            "Epoch 20/20\n",
            "Train Loss: 0.7599\n",
            "Test Metrics - Acc: 0.8440 | Prec: 0.9193 | Rec: 0.8440 | F1: 0.8606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-c688cf0e7004>:211: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Evaluation with Best Model:\n",
            "Accuracy: 0.9220 | Precision: 0.9220\n",
            "Recall: 0.9220 | F1 Score: 0.9220\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ========== Reproducibility Setup ==========\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ========== Data Download ==========\n",
        "!kaggle datasets download -d azouzmaroua/algeria-ultrasound-images-thyroid-dataset-auitd\n",
        "\n",
        "# ========== Data Transformations ==========\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ========== Dataset & DataLoader ==========\n",
        "class ThyroidDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = 2 if \"normal thyroid\" in img_path else (1 if \"Malignant\" in img_path else 0)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def load_dataset(root_dir):\n",
        "    train_paths = glob.glob(os.path.join(root_dir, \"train\", \"*\", \"*.jpg\"))\n",
        "    test_paths = glob.glob(os.path.join(root_dir, \"test\", \"*\", \"*.jpg\"))\n",
        "    return train_paths, test_paths\n",
        "\n",
        "# ========== Data Preparation ==========\n",
        "batch_size = 32\n",
        "zip_path = \"/content/algeria-ultrasound-images-thyroid-dataset-auitd.zip\"\n",
        "extract_path = \"/content/dataset_thyroid\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "dataset_root = os.path.join(extract_path, \"dataset thyroid\")\n",
        "if not os.path.exists(dataset_root):\n",
        "    dataset_root = extract_path\n",
        "\n",
        "train_paths, test_paths = load_dataset(dataset_root)\n",
        "train_dataset = ThyroidDataset(train_paths, transform=train_transforms)\n",
        "test_dataset = ThyroidDataset(test_paths, transform=test_transforms)\n",
        "\n",
        "# Initialize generator for reproducibility\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(SEED)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=worker_init_fn,\n",
        "    generator=generator,\n",
        "    drop_last=True  # Ensures consistent batch sizes\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=worker_init_fn\n",
        ")\n",
        "\n",
        "# ========== Hybrid Model Architecture ==========\n",
        "class HybridCNNGAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridCNNGAT, self).__init__()\n",
        "        self.cnn = models.efficientnet_b4(weights=\"DEFAULT\")\n",
        "        for param in self.cnn.features[:-3].parameters():\n",
        "            param.requires_grad = True\n",
        "        self.cnn.classifier = nn.Identity()\n",
        "        self.fc1 = nn.Linear(1792, 512)\n",
        "        self.gat1 = pyg_nn.GATConv(512, 256, heads=4, concat=True, dropout=0.4)\n",
        "        self.gat2 = pyg_nn.GATConv(256*4, 128, heads=4, concat=True, dropout=0.4)\n",
        "        self.fc2 = nn.Linear(128*4, 3)\n",
        "\n",
        "        # Initialize GAT layers with fixed seeds\n",
        "        torch.manual_seed(SEED)\n",
        "        self.gat1.reset_parameters()\n",
        "        torch.manual_seed(SEED)\n",
        "        self.gat2.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        cnn_features = self.cnn(x)\n",
        "        x = torch.relu(self.fc1(cnn_features))\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ========== Graph Construction ==========\n",
        "def create_edge_index(num_nodes):\n",
        "    edge_index = []\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(i+1, min(i+3, num_nodes)):\n",
        "            edge_index.append([i, j])\n",
        "            edge_index.append([j, i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# ========== Training Setup ==========\n",
        "model = HybridCNNGAT().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ========== Training & Evaluation ==========\n",
        "def train_model():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        edge_index = create_edge_index(len(images)).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, edge_index)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    return total_loss/len(train_loader)\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            edge_index = create_edge_index(len(images)).to(device)\n",
        "            outputs = model(images, edge_index)\n",
        "            preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    precision = precision_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    recall = recall_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# ========== Main Execution ==========\n",
        "num_epochs = 20\n",
        "best_f1 = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_model()\n",
        "    acc, prec, rec, f1 = evaluate_model()\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "# Load best model for final evaluation\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "final_acc, final_prec, final_rec, final_f1 = evaluate_model()\n",
        "print(\"\\nFinal Evaluation with Best Model:\")\n",
        "print(f\"Accuracy: {final_acc:.4f} | Precision: {final_prec:.4f}\")\n",
        "print(f\"Recall: {final_rec:.4f} | F1 Score: {final_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIAptcuDUMTE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBI24NnuUMXu"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# ========== Reproducibility Setup ==========\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True  # Ensures deterministic algorithms\n",
        "torch.backends.cudnn.benchmark = False    # Disables non-deterministic algorithms\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ========== Data Download ==========\n",
        "!kaggle datasets download -d azouzmaroua/algeria-ultrasound-images-thyroid-dataset-auitd\n",
        "\n",
        "# ========== Data Transformations ==========\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ========== Dataset & DataLoader ==========\n",
        "class ThyroidDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = 2 if \"normal thyroid\" in img_path else (1 if \"Malignant\" in img_path else 0)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def load_dataset(root_dir):\n",
        "    train_paths = glob.glob(os.path.join(root_dir, \"train\", \"*\", \"*.jpg\"))\n",
        "    test_paths = glob.glob(os.path.join(root_dir, \"test\", \"*\", \"*.jpg\"))\n",
        "    return train_paths, test_paths\n",
        "\n",
        "# ========== Data Preparation ==========\n",
        "batch_size = 32\n",
        "zip_path = \"/content/algeria-ultrasound-images-thyroid-dataset-auitd.zip\"\n",
        "extract_path = \"/content/dataset_thyroid\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "dataset_root = os.path.join(extract_path, \"dataset thyroid\")\n",
        "if not os.path.exists(dataset_root):\n",
        "    dataset_root = extract_path\n",
        "\n",
        "train_paths, test_paths = load_dataset(dataset_root)\n",
        "train_dataset = ThyroidDataset(train_paths, transform=train_transforms)\n",
        "test_dataset = ThyroidDataset(test_paths, transform=test_transforms)\n",
        "\n",
        "# Initialize generator for reproducibility\n",
        "def worker_init_fn(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(SEED)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=worker_init_fn,\n",
        "    generator=generator,\n",
        "    drop_last=True  # Ensures consistent batch sizes\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    worker_init_fn=worker_init_fn\n",
        ")\n",
        "\n",
        "# ========== Hybrid Model Architecture ==========\n",
        "class HybridCNNGAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridCNNGAT, self).__init__()\n",
        "        self.cnn = models.efficientnet_b4(weights=\"DEFAULT\")\n",
        "        for param in self.cnn.features[:-3].parameters():\n",
        "            param.requires_grad = True\n",
        "        self.cnn.classifier = nn.Identity()\n",
        "        self.fc1 = nn.Linear(1792, 512)\n",
        "        self.gat1 = pyg_nn.GATConv(512, 256, heads=4, concat=True, dropout=0.4)\n",
        "        self.gat2 = pyg_nn.GATConv(256*4, 128, heads=4, concat=True, dropout=0.4)\n",
        "        self.fc2 = nn.Linear(128*4, 3)\n",
        "\n",
        "        # Initialize GAT layers with fixed seeds\n",
        "        torch.manual_seed(SEED)\n",
        "        self.gat1.reset_parameters()\n",
        "        torch.manual_seed(SEED)\n",
        "        self.gat2.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        cnn_features = self.cnn(x)\n",
        "        x = torch.relu(self.fc1(cnn_features))\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ========== Graph Construction ==========\n",
        "def create_edge_index(num_nodes):\n",
        "    edge_index = []\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(i+1, min(i+3, num_nodes)):\n",
        "            edge_index.append([i, j])\n",
        "            edge_index.append([j, i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# ========== Training Setup ==========\n",
        "model = HybridCNNGAT().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ========== Training & Evaluation ==========\n",
        "def train_model():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        edge_index = create_edge_index(len(images)).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, edge_index)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "    return total_loss/len(train_loader)\n",
        "\n",
        "def evaluate_model():\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            edge_index = create_edge_index(len(images)).to(device)\n",
        "            outputs = model(images, edge_index)\n",
        "            preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    precision = precision_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    recall = recall_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(true_labels, preds, average='weighted', zero_division=1)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# ========== Main Execution ==========\n",
        "num_epochs = 20\n",
        "best_f1 = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_model()\n",
        "    acc, prec, rec, f1 = evaluate_model()\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "# Load best model for final evaluation\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "final_acc, final_prec, final_rec, final_f1 = evaluate_model()\n",
        "print(\"\\nFinal Evaluation with Best Model:\")\n",
        "print(f\"Accuracy: {final_acc:.4f} | Precision: {final_prec:.4f}\")\n",
        "print(f\"Recall: {final_rec:.4f} | F1 Score: {final_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKY756geUMZ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCPHVVeVUMbr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX3UtnyYUMdn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6tuwRCkUMg7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0LbF2oaUMiz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRWIqh9JUMnd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz1yfe1vN_qu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoHC7G_JSa6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lktgCkAhSa9w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N9TOUF4Sbms"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
